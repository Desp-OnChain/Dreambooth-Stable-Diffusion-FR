{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa2c1ada",
   "metadata": {
    "id": "aa2c1ada"
   },
   "source": [
    "# Dreambooth\n",
    "### Implémentation originale du notebook par Joe Penna (@MysteryGuitarM sur Twitter) - Améliorations par David Bielejeski et Léo \"Desp\" (@Desp_OnChain sur Twitter)\n",
    "\n",
    "Pour plus d'informations, voir le README de:\n",
    "https://github.com/Desp-OnChain/Dreambooth-Stable-Diffusion-FR\n",
    "\n",
    "## Instructions\n",
    "- Tout d'abord, suivez les instructions présentées dans ce thread: https://twitter.com/Desp_OnChain/status/1577609784441933824?s=20&t=KLrYD4GGif2evwKaJYpeLg\n",
    "- Ensuite, remplissez la cellule intitulée *A COMPLETER* ci-dessous avec vos valeurs comme décrit ci-dessous\n",
    "\n",
    "### Récupérez votre token d'authentification sur huggingface\n",
    "\n",
    "- Connectez-vous à votre compte HuggingFace\n",
    "- Acceptez les termes d'utilisations du modèle à l'adresse suivante: https://huggingface.co/CompVis/stable-diffusion-v-1-4-original\n",
    "- Rendez vous ici: https://huggingface.co/settings/tokens\n",
    "- Cliquez sur New Token, donnez lui un nom, mettez le role à `read` puis cliquez sur Generate a token\n",
    "- Copiez ensuite ce token et remplacez `Mon_token` par votre token dans la cellule suivante.\n",
    "\n",
    "### Uploadez vos images d'entrainement\n",
    "Uploadez 10-20 images de quelqu'un sur imgur, et ajoutez les lien directs vers les images à la liste d'urls en respectant le format indiqué.\n",
    "ATTENTION: Faites attention à bien utiliser un nombre pair d'images sinon l'entrainement s'arrête à 1500 étapes.\n",
    "Il faut environ:\n",
    "\n",
    "*   2-3 corps complet\n",
    "*   3-5 haut du corps\n",
    "*   5-12 visage\n",
    "\n",
    "Les images doivent être:\n",
    "\n",
    "- Similaires au genre d'images que vous souhaitez générer (donc pas de selfies la plupart du temps).\n",
    "- Autant différentes les unes des autres que possible (dans le contexte, la position du sujet, etc).\n",
    "\n",
    "### Indiquez votre token et votre classe\n",
    "\n",
    "Remplacez 'gusfring' et 'person' par le nom et la classe désirée, par exemple 'felix' et 'cat' si vous voulez générer des images d'un chat appelé felix.\n",
    "Si vous changez la classe, remplacez également `person = True` par `person = False`, ce qui permettra de générer de nouvelles images de régularisation.\n",
    "\n",
    "### Etapes d'entrainement\n",
    "\n",
    "Libre à vous d'ajouster le nombre d'étapes d'entrainement pour voir si cela peut améliorer vos résultats.\n",
    "\n",
    "### Finalement, cliquez sur l'icone constituée de deux triangles ci-dessus en haut de l'onglet, située à droite de la flèche circulaire, juste en dessous du nom du fichier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e84baa-868f-4621-93e3-0f6e00273b1a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# A COMPLETER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91cd3ad-f7c1-45cb-bfa1-fc03781f9e65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Ajoutez ici votre token d'identification HuggingFace\n",
    "auth_token = \"mon_token\"\n",
    "\n",
    "\n",
    "#Ajoutez ici les urls de vos images\n",
    "urls = [\n",
    "    \"https://i.imgur.com/image.jpg\",\n",
    "    \"https://i.imgur.com/image.jpg\",\n",
    "    \"https://i.imgur.com/image.jpg\",\n",
    "    \"https://i.imgur.com/image.jpg\",\n",
    "    \"https://i.imgur.com/image.jpg\",\n",
    "    \"https://i.imgur.com/image.jpg\",\n",
    "    \"https://i.imgur.com/image.jpg\",\n",
    "    \"https://i.imgur.com/image.jpg\",\n",
    "    \"https://i.imgur.com/image.jpg\",\n",
    "    \"https://i.imgur.com/image.jpg\",\n",
    " # Vous pouvez ajoutez plus d'images ici en suivant le même principe: lien entre guillemets suivi d'une virgule \n",
    "]\n",
    "\n",
    "# Remplacez le nom entre guillemets par le nom que vous voulez\n",
    "my_token = 'gusfring'\n",
    "\n",
    "# Si votre sujet est une personne, laissez 'person', sinon remplacez avec le nom de votre classe en anglais (ex: 'dog' si votre sujet est un chien)\n",
    "my_class = 'person'\n",
    "\n",
    "# Si vous avez modifié la classe juste au dessus, remplacez ici True par False\n",
    "person = True\n",
    "\n",
    "# Nombre d'étapes d'entrainement, vous pouvez laisser cette valeur ou la modifier pour essayer d'améliorer vos résultats\n",
    "max_training_steps = 1616"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b971cc0",
   "metadata": {
    "id": "7b971cc0",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Création de l'environnement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1bc458-091b-42f4-a125-c3f0df20f29d",
   "metadata": {
    "id": "9e1bc458-091b-42f4-a125-c3f0df20f29d",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#BUILD ENV\n",
    "!pip install omegaconf\n",
    "!pip install einops\n",
    "!pip install pytorch-lightning==1.6.5\n",
    "!pip install test-tube\n",
    "!pip install transformers\n",
    "!pip install kornia\n",
    "!pip install -e git+https://github.com/CompVis/taming-transformers.git@master#egg=taming-transformers\n",
    "!pip install -e git+https://github.com/openai/CLIP.git@main#egg=clip\n",
    "!pip install setuptools==59.5.0\n",
    "!pip install pillow==9.0.1\n",
    "!pip install torchmetrics==0.6.0\n",
    "!pip install -e .\n",
    "!pip install protobuf==3.20.1\n",
    "!pip install gdown\n",
    "!pip install pydrive\n",
    "!pip install -qq diffusers[\"training\"]==0.3.0 transformers ftfy\n",
    "!pip install -qq \"ipywidgets>=7,<8\"\n",
    "!pip install huggingface_hub\n",
    "!pip install ipywidgets==7.7.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5acbe7",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "## Téléchargement du modèle\n",
    "from huggingface_hub import hf_hub_download\n",
    "downloaded_model_path = hf_hub_download(\n",
    " repo_id=\"CompVis/stable-diffusion-v-1-4-original\",\n",
    " filename=\"sd-v1-4.ckpt\",\n",
    " use_auth_token=auth_token\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55afedc-5fb3-40c7-8e62-4602cc9974ff",
   "metadata": {},
   "source": [
    "Si un message indiquant \"Click to show javascript error.\" s'affiche ci-dessus, ne vous en faites pas c'est seulement une erreur d'affichage, vous pouvez l'ignorer ou rafraîchir la page pour résoudre le problème."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00275cd4",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "## Déplacement et renommage du modèle \"model.ckpt\"\n",
    "actual_locations_of_model_blob = !readlink -f {downloaded_model_path}\n",
    "!mv {actual_locations_of_model_blob[-1]} model.ckpt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d1d11a",
   "metadata": {
    "id": "17d1d11a",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Images de régularisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed07a5df",
   "metadata": {
    "id": "ed07a5df"
   },
   "source": [
    "L'entrainement apprend votre token au modèle **mais** ré-entraine également la classe.\n",
    "\n",
    "Après tests, il sembleraient que les images de reg n'affectent pas trop le modèle. Cependant, elles affectent énormément votre classe, ce qui va donc affecter vos générations.\n",
    "\n",
    "Vous pouvez soit générer vos images, soit utiliser les repos ci-dessous pour rapidement générer 1500 images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mxPL2O0OLvBW",
   "metadata": {
    "id": "mxPL2O0OLvBW",
    "tags": []
   },
   "source": [
    "## Téléchargement des images de régularisation pré-générées\n",
    "\n",
    "L'équipe de Joe a créé les ensembles d'images suivants:\n",
    "\n",
    "* man_euler - fourni par Niko Pueringer (Corridor Digital) - euler @ 40 steps, CFG 7.5\n",
    "* man_unsplash - images de différents photographes\n",
    "* person_ddim\n",
    "* woman_ddim - fourni par David Bielejeski - ddim @ 50 steps, CFG 10.0\n",
    "\n",
    "`person_ddim` recommandé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7EydXCjOV1v",
   "metadata": {
    "id": "e7EydXCjOV1v",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Récupération des images de régularisation\n",
    "if person:\n",
    "    dataset=\"person_ddim\"\n",
    "    !git clone https://github.com/djbielejeski/Stable-Diffusion-Regularization-Images-{dataset}.git\n",
    "\n",
    "    !mkdir -p outputs/txt2img-samples/samples/{dataset}\n",
    "    !mv -v Stable-Diffusion-Regularization-Images-{dataset}/{dataset}/*.* outputs/txt2img-samples/samples/{dataset}\n",
    "else:\n",
    "    !python scripts/stable_txt2img.py \\\n",
    "     --seed 10 \\\n",
    "     --ddim_eta 0.0 \\\n",
    "     --n_samples 1 \\\n",
    "     --n_iter 200 \\\n",
    "     --scale 10.0 \\\n",
    "     --ddim_steps 50 \\\n",
    "     --ckpt model.ckpt \\\n",
    "     --prompt {my_class}\n",
    "    !apt-get install -y zip\n",
    "    !zip -r all_images.zip outputs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5a6e8f",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#@title Download and check the images you have just added\n",
    "import os\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def image_grid(imgs, rows, cols):\n",
    " assert len(imgs) == rows*cols\n",
    "\n",
    " w, h = imgs[0].size\n",
    " grid = Image.new('RGB', size=(cols*w, rows*h))\n",
    " grid_w, grid_h = grid.size\n",
    "\n",
    " for i, img in enumerate(imgs):\n",
    "  grid.paste(img, box=(i%cols*w, i//cols*h))\n",
    " return grid\n",
    "\n",
    "def download_image(url):\n",
    " try:\n",
    "  response = requests.get(url)\n",
    " except:\n",
    "  return None\n",
    " return Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
    "\n",
    "images = list(filter(None,[download_image(url) for url in urls]))\n",
    "save_path = \"./training_samples\"\n",
    "if not os.path.exists(save_path):\n",
    " os.mkdir(save_path)\n",
    "[image.save(f\"{save_path}/{i}.png\", format=\"png\") for i, image in enumerate(images)]\n",
    "image_grid(images, 1, len(images))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4e50df",
   "metadata": {
    "id": "ad4e50df"
   },
   "source": [
    "# Entrainement\n",
    "\n",
    "Si vous entrainez sur une personne ou un sujet, faites attention aux images générées ici: `logs/{folder}/images/train/samples_scaled_gs-00xxxx`\n",
    "\n",
    "Si vous entrainez sur un style, surveillez ce dossier: `logs/{folder}/images/train/samples_gs-00xxxx`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2051b9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Modification du fichier personalized.py\n",
    "\n",
    "Joe recommande d'utiliser le nom d'une célébrité qui:\n",
    "1) vous ressemble un peu.\n",
    "2) est bien générée par Stable Diffusion (vous pouvez vérifier en tapant son nom sur DreamStudio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5a69dd",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%%writefile ldm/data/personalized.py\n",
    "# %load ldm/data/personalized.py\n",
    "import os\n",
    "import numpy as np\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "import random\n",
    "\n",
    "training_templates_smallest = [\n",
    "    my_token + ' {}',\n",
    "]\n",
    "\n",
    "reg_templates_smallest = [\n",
    "    '{}',\n",
    "]\n",
    "\n",
    "imagenet_templates_small = [\n",
    "\n",
    "    '{}',\n",
    "]\n",
    "\n",
    "imagenet_dual_templates_small = [\n",
    "    '{} with {}'\n",
    "]\n",
    "\n",
    "per_img_token_list = [\n",
    "    'א', 'ב', 'ג', 'ד', 'ה', 'ו', 'ז', 'ח', 'ט', 'י', 'כ', 'ל', 'מ', 'נ', 'ס', 'ע', 'פ', 'צ', 'ק', 'ר', 'ש', 'ת',\n",
    "]\n",
    "\n",
    "\n",
    "class PersonalizedBase(Dataset):\n",
    "    def __init__(self,\n",
    "                 data_root,\n",
    "                 size=None,\n",
    "                 repeats=100,\n",
    "                 interpolation=\"bicubic\",\n",
    "                 flip_p=0.0,\n",
    "                 set=\"train\",\n",
    "                 placeholder_token=\"dog\",\n",
    "                 per_image_tokens=False,\n",
    "                 center_crop=False,\n",
    "                 mixing_prob=0.25,\n",
    "                 coarse_class_text=None,\n",
    "                 reg=False\n",
    "                 ):\n",
    "\n",
    "        self.data_root = data_root\n",
    "\n",
    "        self.image_paths = [os.path.join(\n",
    "            self.data_root, file_path) for file_path in os.listdir(self.data_root)]\n",
    "\n",
    "        # self._length = len(self.image_paths)\n",
    "        self.num_images = len(self.image_paths)\n",
    "        self._length = self.num_images\n",
    "\n",
    "        self.placeholder_token = placeholder_token\n",
    "\n",
    "        self.per_image_tokens = per_image_tokens\n",
    "        self.center_crop = center_crop\n",
    "        self.mixing_prob = mixing_prob\n",
    "\n",
    "        self.coarse_class_text = coarse_class_text\n",
    "\n",
    "        if per_image_tokens:\n",
    "            assert self.num_images < len(\n",
    "                per_img_token_list), f\"Can't use per-image tokens when the training set contains more than {len(per_img_token_list)} tokens. To enable larger sets, add more tokens to 'per_img_token_list'.\"\n",
    "\n",
    "        if set == \"train\":\n",
    "            self._length = self.num_images * repeats\n",
    "\n",
    "        self.size = size\n",
    "        self.interpolation = {\"linear\": PIL.Image.LINEAR,\n",
    "                              \"bilinear\": PIL.Image.BILINEAR,\n",
    "                              \"bicubic\": PIL.Image.BICUBIC,\n",
    "                              \"lanczos\": PIL.Image.LANCZOS,\n",
    "                              }[interpolation]\n",
    "        self.flip = transforms.RandomHorizontalFlip(p=flip_p)\n",
    "        self.reg = reg\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._length\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        example = {}\n",
    "        image = Image.open(self.image_paths[i % self.num_images])\n",
    "\n",
    "        if not image.mode == \"RGB\":\n",
    "            image = image.convert(\"RGB\")\n",
    "\n",
    "        placeholder_string = self.placeholder_token\n",
    "        if self.coarse_class_text:\n",
    "            placeholder_string = f\"{self.coarse_class_text} {placeholder_string}\"\n",
    "\n",
    "        if not self.reg:\n",
    "            text = random.choice(training_templates_smallest).format(\n",
    "                placeholder_string)\n",
    "        else:\n",
    "            text = random.choice(reg_templates_smallest).format(\n",
    "                placeholder_string)\n",
    "\n",
    "        example[\"caption\"] = text\n",
    "\n",
    "        # default to score-sde preprocessing\n",
    "        img = np.array(image).astype(np.uint8)\n",
    "\n",
    "        if self.center_crop:\n",
    "            crop = min(img.shape[0], img.shape[1])\n",
    "            h, w, = img.shape[0], img.shape[1]\n",
    "            img = img[(h - crop) // 2:(h + crop) // 2,\n",
    "                      (w - crop) // 2:(w + crop) // 2]\n",
    "\n",
    "        image = Image.fromarray(img)\n",
    "        if self.size is not None:\n",
    "            image = image.resize((self.size, self.size),\n",
    "                                 resample=self.interpolation)\n",
    "\n",
    "        image = self.flip(image)\n",
    "        image = np.array(image).astype(np.uint8)\n",
    "        example[\"image\"] = (image / 127.5 - 1.0).astype(np.float32)\n",
    "        return example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a9be9f-2804-4fa3-9ee3-d666eb790432",
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo \"my_token=\\\"\"$my_token\"\\\"\\n\" | cat - ldm/data/personalized.py > temp && mv temp ldm/data/personalized.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642e7402-bd60-4d00-85f1-b74e614dbcbd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Lancement de l'entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa5dd66-2ca0-4819-907e-802e25583ae6",
   "metadata": {
    "id": "6fa5dd66-2ca0-4819-907e-802e25583ae6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DEBUT DE L'ENTRAINEMENT\n",
    "project_name = my_token\n",
    "\n",
    "reg_data_root = \"/workspace/Dreambooth-Stable-Diffusion-FR/outputs/txt2img-samples/samples/\" + dataset\n",
    "\n",
    "!rm -rf training_samples/.ipynb_checkpoints\n",
    "!python \"main.py\" \\\n",
    " --base configs/stable-diffusion/v1-finetune_unfrozen.yaml \\\n",
    " -t \\\n",
    " --actual_resume \"model.ckpt\" \\\n",
    " --reg_data_root {reg_data_root} \\\n",
    " -n {project_name} \\\n",
    " --gpus 0, \\\n",
    " --data_root \"/workspace/Dreambooth-Stable-Diffusion-FR/training_samples\" \\\n",
    " --max_training_steps {max_training_steps} \\\n",
    " --class_word {my_class} \\\n",
    " --no-test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc49d0bd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Pruning (de 12GB à 2GB)\n",
    "Réduction de la taille du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53955afc",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "directory_paths = !ls -d logs/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab61513",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Cette version réduit d'environ 10GB le fichier ckpt\n",
    "last_checkpoint_file = directory_paths[-1] + \"/checkpoints/last.ckpt\"\n",
    "!python \"prune_ckpt.py\" --ckpt {last_checkpoint_file}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0b127e",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "last_checkpoint_file_pruned = directory_paths[-1] + \"/checkpoints/last-pruned.ckpt\"\n",
    "training_samples = !ls training_samples\n",
    "date_string = !date +\"%Y-%m-%dT%H-%M-%S\"\n",
    "file_name = date_string[-1] + \"_\" + project_name + \"_\" + str(len(training_samples)) + \"_training_images_\" +  str(max_training_steps) + \"_max_training_steps_\" + my_class + \"_class_word.ckpt\"\n",
    "!mkdir -p trained_models\n",
    "!mv {last_checkpoint_file_pruned} trained_models/{file_name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a088b0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vous pouvez maintenant télécharger cotre modèle dans le dossier `trained_models` et l'utiliser dans le repo Stable Diffusion que vous souhaitez!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a90ac5c",
   "metadata": {},
   "source": [
    "# Note importante!\n",
    "\n",
    "Pour utiliser votre token, suivre le format suivant: `<token> <class>` ex: `joepenna person` pas juste `joepenna`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28d0139",
   "metadata": {},
   "source": [
    "## Générez des images avec votre modèle entrainé!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b11c7c0-8875-4e5d-b365-20fd71a78e5c",
   "metadata": {},
   "source": [
    "Retrouvez vos images générées dans `/outputs/txt2img-samples/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ca1870-8d81-44c4-9b49-afa4a8a5a164",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"/workspace/Dreambooth-Stable-Diffusion-FR/trained_models/\" + file_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084461ed-3af0-4d8d-85ee-e563c556f3fc",
   "metadata": {},
   "source": [
    "Modifiez ici la dernière ligne en remplacant la description pas celle que vous souhaitez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ddb03b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python scripts/stable_txt2img.py \\\n",
    " --ddim_eta 0.0 \\\n",
    " --n_samples 1 \\\n",
    " --n_iter 4 \\\n",
    " --scale 7.0 \\\n",
    " --ddim_steps 50 \\\n",
    " --ckpt $model_path \\\n",
    " --prompt 'Picture of gusfring person standing in front of the Eiffel tower'"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
